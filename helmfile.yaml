repositories:
  - name: stable
    url: https://charts.helm.sh/stable
  - name: prometheus-community
    url: https://prometheus-community.github.io/helm-charts
  - name: ingress-nginx
    url: https://kubernetes.github.io/ingress-nginx
  - name: kiwigrid
    url: https://kiwigrid.github.io
  - name: jetstack
    url: https://charts.jetstack.io
  - name: loki
    url: https://grafana.github.io/loki/charts
  - name: itzg
    url: https://itzg.github.io/minecraft-server-charts/
  - name: k8s-at-home
    url: https://k8s-at-home.com/charts/
  - name: bitnami
    url: https://charts.bitnami.com/bitnami
  - name: presslabs
    url: https://presslabs.github.io/charts

releases:
  - name: cert-manager
    chart: jetstack/cert-manager
    version: ~0.12.0
    namespace: cert-manager
  - name: goldpinger
    chart: stable/goldpinger
    version: ~2.0.1
    values:
      - resources:
          limits:
            memory: 50Mi
          requests:
            memory: 50Mi
        serviceMonitor:
          enabled: true
          namespace: default
  - name: nginx-ingress
    chart: ingress-nginx/ingress-nginx
    version: ~3.9.0
    values:
      - controller:
          hostNetwork: true
          dnsPolicy: ClusterFirstWithHostNet
          nodeSelector:
            kubernetes.io/hostname: nimbus
          minAvailable: 0
          tolerations:
            - key: cloud
              operator: Exists
              effect: NoSchedule
          resources:
           limits:
             memory: 400Mi
           requests:
             cpu: 100m
             memory: 400Mi
        defaultBackend:
          minAvailable: 0
          resources:
            limits:
              cpu: 10m
              memory: 20Mi
            requests:
              cpu: 10m
              memory: 20Mi
          service:
            omitClusterIP: true
        rbac:
          create: true
  - name: home-assistant
    chart: k8s-at-home/home-assistant
    version: ~1.0.5
    values:
      - persistence:
          enabled: true
          size: 32Gi
          accessMode: ReadWriteMany
          storageClass: "cephfs"
        probes:
          liveness:
            enabled: false
        # nodeSelector:
        #   kubernetes.io/hostname: absis
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
                - matchExpressions:
                  - key: "kubernetes.io/hostname"
                    operator: In
                    values: ["absis", "leviathan", "smicro1"]
        monitoring:
          enabled: true
        resources:
          limits:
           memory: 2Gi
          requests:
           cpu: 500m
           memory: 2Gi
      - values/home-assistant_values.yaml
  - name: transmission-ovpn
    chart: ./transmission-ovpn
    version: ~1.0
    values:
      - resources:
          requests:
            cpu: .25
            memory: 5Gi
          limits:
            memory: 5Gi
      - values/transmission-ovpn.yaml
  - name: radarr
    chart: ./radarr
    version: ~1.0
    values:
      - values/radarr.yaml
  - name: sonarr
    chart: ./sonarr
    version: ~1.0
    values:
      - values/sonarr.yaml
  - name: jackett
    chart: ./jackett
    version: ~1.0
    values:
      - values/jackett.yaml
  - name: wobbling-crab
    chart: ./ombi
    version: ~0.1.0
    values:
      - values/ombi_values.yaml
  - name: solemn-echidna
    chart: ./plex
    version: ~0.3.1
    values:
      - values/plex_values.yaml
  - name: prometheus
    chart: prometheus-community/kube-prometheus-stack
    version: ^9.4.10
    values:
      - alertmanager:
          alertmanagerSpec:
            resources:
              requests:
                memory: 400Mi
              limits:
                memory: 400Mi
            storageSpec:
              volumeClaimTemplate:
               spec:
                 storageClassName: cephfs
                 accessModes: ["ReadWriteMany"]
                 resources:
                   requests:
                     storage: 5Gi
        prometheusOperator:
          resources:
            limits:
              cpu: 200m
              memory: 200Mi
            requests:
              cpu: 100m
              memory: 100Mi
        prometheus:
          prometheusSpec:
            securityContext:
              runAsNonRoot: false
              runAsUser: 0
              fsGroup: 0
            retention: 12w
            storageSpec:
              volumeClaimTemplate:
               spec:
                 storageClassName: cephfs
                 accessModes: ["ReadWriteMany"]
                 resources:
                   requests:
                     storage: 100Gi
            serviceMonitorSelectorNilUsesHelmValues: false
            additionalScrapeConfigs:
            - job_name: 'ceph'
              honor_labels: true
              static_configs:
              - targets:
                - "10.0.0.1:9283"
                - "10.0.0.3:9283"
                - "10.0.0.6:9283"
                labels: { "cluster": "stapler1" }
            resources:
              requests:
                memory: 5Gi
              limits:
                memory: 5Gi
        prometheus-node-exporter:
          resources:
            limits:
              cpu: 200m
              memory: 50Mi
            requests:
              cpu: 100m
              memory: 30Mi
        grafana:
          enabled: true
          ingress:
            enabled: true
            annotations:
              cert-manager.io/cluster-issuer: letsencrypt-prod
            hosts:
              - graph.staplerstation.com
            tls:
            - hosts:
                - graph.staplerstation.com
              secretName: grafana-ingress
          grafana.ini:
            server:
              domain: graph.staplerstation.com
          resources:
            limits:
              memory: 1Gi
            requests:
              memory: 1Gi
          persistence:
            enabled: true
            size: 32Gi
            accessMode: ReadWriteMany
            storageClassName: "cephfs"
          extraContainers: |
            - name: renderer
              image: grafana/grafana-image-renderer:latest
          env:
            GF_RENDERING_SERVER_URL: http://localhost:8081/render
            GF_RENDERING_CALLBACK_URL: http://localhost:3000/
  - name: loki
    chart: loki/loki-stack
    version: 2.0.2
    values:
      - loki:
          resources:
            limits:
              memory: 512Mi
            requests:
              cpu: 100m
              memory: 512Mi
  - name: unifi-exporter
    chart: ./unifi-exporter
    version: ~0.1.0
    values:
      - config:
          listen:
            address: :9130
            metricspath: /metrics
      - values/unifi_exporter.yaml
  - name: zoneminder
    chart: ./zoneminder
    version: ~0.1.0
    values:
      - resources:
          requests:
            memory: 2Gi
            cpu: 2
          limits:
            memory: 2Gi
        service:
          type: LoadBalancer
      - values/zoneminder_values.yaml
  - name: metallb
    chart: stable/metallb
    version: ~0.12.0
    values:
    - configInline:
        address-pools:
        - name: default
          protocol: layer2
          addresses:
          - 192.168.1.220-192.168.1.240
      controller:
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
      speaker:
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
                - matchExpressions:
                  - key: "kubernetes.io/hostname"
                    operator: In
                    values: ["absis", "leviathan", "smicro1"]
